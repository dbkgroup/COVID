---
title: "COVID discovery study"
---


```{r}
library(formattable)
library(tidyverse)
library(magrittr)
library(glue)
source("Data_prep.R")
source("Data_viz.R")
source("Data_processing.R")
source("Models_toolbox.R")
```



Loading Thermo's Compound Discoverer (CD) processed data

DiscoveryStudyB2-B5_pos.csv : hold exported results from Compound Discoverer (Thermo) ESI+ mode
DiscoveryStudyB2-B5_neg.csv : hold exported results from Compound Discoverer (Thermo) ESI- mode

DisciveryStudy_RunOrder.csv : acquisition sequence order - important for data normalization, the sequence was the same in ESI+ and ESI-

B2-B5_sample_mapping.csv : hold the information on sample mapping between hospital sample ID (important to relate to metadata) and LC-MS run ID (important to relate to acquired data)

! Remove dat aof birth !!!
COVID_all_metadata.csv : metadata associated to samples and patients 


```{r Load data, message=FALSE, include=FALSE}
data_pos <- read_csv("Data/DiscoveryStudyB2-B5_pos.csv", guess_max = 8000)
data_neg <- read_csv("Data/DiscoveryStudyB2-B5_neg.csv", guess_max = 8000)
data_order <- read_csv("Data/DisciveryStudy_RunOrder.csv", guess_max = 8000)
data_info <- read_csv("Data/B2-B5_sample_mapping.csv")
data_info_all <- read_csv("Data/COVID_all_metadata.csv")

data_info_plus <- data_order %>%
  drop_na() %>%
  separate(Sample, c("Condition", "Study", "Batch", "Sample"), sep = "_") %>%
  select(-c("Study", "Condition")) %>%
  left_join(data_info) 


# the ESI+ B2_SQA75 was forgotten from the in the pre-processing therefore mission to avoid error in the following code this sample is removed. 
data_pos_info_all <- data_info_plus %>% 
  filter(!(Batch == "B2" & Sample == "SQA75")) %>%
  left_join(data_info_all, by = "SampleID")



# The ESI- B4_GBX was actually named GB1 in the data pre-processing step and therefore it is renamed here to avoid conflicts in later code.
data_neg_info_all <- data_info_plus %>% 
  left_join(data_info_all, by = "SampleID") 

data_neg_info_all$Sample <- ifelse(data_neg_info_all$Batch == "B4" & data_neg_info_all$Sample == "GBX", "GB1", data_neg_info_all$Sample)

```

```{r Create area eset}
#eset_CD_area_pos <- covid_transform_to_eset(data_pos, data_pos_info_all %>% filter(Sample != "SQA75" | Batch != "B2") , normalized_areas = F, background = F, normalized = T)

eset_CD_area_pos <- covid_transform_to_eset(data_pos, data_pos_info_all, normalized_areas = F, background = F, normalized = T)

eset_CD_area_neg <- covid_transform_to_eset(data_neg, data_neg_info_all, normalized_areas = F, background = F, normalized = T)
```

```{r echo=FALSE}
formattable(get_basic_stats(get_compound_info_short_list(data_pos), "ESI+"), align =c("l","c"), 
            list(`Criteria` = formatter(
              "span", style = ~ style(color = "grey",font.weight = "bold"))))
```

```{r echo=FALSE}
formattable(get_basic_stats(get_compound_info_short_list(data_neg), "ESI-"), align =c("l","c"), 
            list(`Criteria` = formatter(
              "span", style = ~ style(color = "grey",font.weight = "bold"))))
```


PCA plot visualization of the raw areas by batch and group in ESI+ and ESI-
The data shows relatively little variation by batch but significant time drift in the QC

```{r}
p1_a <- get_pca_by_batch(eset_CD_area_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by batch", title_center = F)
p2_a <- get_pca_by_group(eset_CD_area_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by group", title_center = F)

p3_a <- get_pca_by_batch(eset_CD_area_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by batch", title_center = F)
p4_a <- get_pca_by_group(eset_CD_area_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by group", title_center = F)

gridExtra::grid.arrange(p1_a, p2_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI+", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))

gridExtra::grid.arrange(p3_a, p4_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI-", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))
```

Test the time drift QC based normalization on a compound in ESI+
```{r}
test_set <- eset_CD_area_pos[eset_CD_area_pos@featureData$Compound == "165.07877_2.583",]
eset_test_norm1 <- covid_normalize_by_batch_plot_correction(test_set)

```

Test the time drift QC based normalization on a compound in ESI-
```{r}
test_set <- eset_CD_area_neg[eset_CD_area_neg@featureData$Compound == "264.11096_5.361",]
eset_test_norm1 <- covid_normalize_by_batch_plot_correction(test_set)

```

Normalize the ESI+ data for QC based time drift per batch (each batch separately)
This part can take a lot of time

```{r Whitin batch normalization}
t_start <- Sys.time()
eset_norm1_pos <- covid_normalize_by_batch(eset_CD_area_pos)
Sys.time() - t_start
```

Normalize the ESI+ data for QC based time drift per batch (each batch separately)
This part can take a lot of time
```{r Whitin batch normalization}
t_start <- Sys.time()
eset_norm1_neg <- covid_normalize_by_batch(eset_CD_area_neg)
Sys.time() - t_start
```


Check on QC based time drift correction 
```{r}
p1_a <- get_pca_by_batch(eset_norm1_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by batch", title_center = F)
p2_a <- get_pca_by_group(eset_norm1_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by group", title_center = F)

p3_a <- get_pca_by_batch(eset_norm1_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by batch", title_center = F)
p4_a <- get_pca_by_group(eset_norm1_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by group", title_center = F)

gridExtra::grid.arrange(p1_a, p2_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI+", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))

gridExtra::grid.arrange(p3_a, p4_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI-", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))
```


Normalize between batches ESI+
```{r Between batch normalization}
source("Data_processing.R")
t_start <- Sys.time()
eset_norm2_pos <- covid_normalize_between_batches(eset_norm1_pos)
Sys.time() - t_start   
```



Normalize between batches ESI-
```{r Between batch normalization}
source("Data_processing.R")
t_start <- Sys.time()
eset_norm2_neg <- covid_normalize_between_batches(eset_norm1_neg)
Sys.time() - t_start   
```



Check on data after both normalizations  
```{r}
p1_a <- get_pca_by_batch(eset_norm2_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by batch", title_center = F)
p2_a <- get_pca_by_group(eset_norm2_pos, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI+ by group", title_center = F)

p3_a <- get_pca_by_batch(eset_norm2_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by batch", title_center = F)
p4_a <- get_pca_by_group(eset_norm2_neg, c("QC", "Sample", "IQA", "SQA"), labels = F, title = "ESI- by group", title_center = F)

gridExtra::grid.arrange(p1_a, p2_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI+", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))

gridExtra::grid.arrange(p3_a, p4_a, nrow = 1, ncol=2, respect = T, padding = unit(1, "mm"), top = textGrob("PCA for all injections ESI-", gp=gpar(fontfamily = "sans", fontsize=15,font=2)), widths = unit(c(93,95), c("mm", "mm")))
```


As normalization is time consuming activity I like to save the results so I can restart on later dates form here
```{r Save / Load normalized data sets}
save(eset_norm2_pos, file = "Data/Norm2_eset_pos.RData")

load(file = "Data/Norm2_eset_pos.RData")
```

```{r Save / Load normalized data sets}
save(eset_norm2_neg, file = "Data/Norm2_eset_neg.RData")

load(file = "Data/Norm2_eset_neg.RData")
```


## Data filtering

Remove all compounds where 20% of the QC were not detected and 75% of the samples were not detected
Remove all compounds where Predicted composition failed
```{r}
#ESI+
data_pos <- eset_norm2_pos %>% remove_compounds(c("QC"), 0.2) %>% remove_compounds(c("Sample"), 0.75)
data_pos_filter <- data_pos[data_pos@featureData$Predicted_Composition == "Full match",]

#ESI-
data_neg <- eset_norm2_neg %>% remove_compounds(c("QC"), 0.2) %>% remove_compounds(c("Sample"), 0.75)
data_neg_filter <- data_neg[data_neg@featureData$Predicted_Composition == "Full match",]
```

## Add Labels of interest
We are adding here a logical version (for models) and character version (for visuals)
```{r}
#ESI+
data_pos_filter@phenoData$Severe = case_when(
  data_pos_filter@phenoData$Severity == "Mild" ~ F,
  data_pos_filter@phenoData$Severity == "Int" ~ F,
  data_pos_filter@phenoData$Severity == "Severe" ~ T,
  TRUE ~ NA)

data_pos_filter@phenoData$SevereL = case_when(
  data_pos_filter@phenoData$Severity == "Mild" ~ "Mild",
  data_pos_filter@phenoData$Severity == "Int" ~ "Mild",
  data_pos_filter@phenoData$Severity == "Intermediate" ~ "Mild",
  data_pos_filter@phenoData$Severity == "Severe" ~ "Severe",
  TRUE ~ as.character(NA))

data_pos_filter@phenoData$Deceased = case_when(
  data_pos_filter@phenoData$Outcome == "Discharge" ~ F,
  data_pos_filter@phenoData$Outcome == "Deceased" ~ T,
  data_pos_filter@phenoData$Outcome == "Ongoing (COV2 negative, currently in neuro rehab)" ~ F,
  TRUE ~ NA)

data_pos_filter@phenoData$DeceasedL = case_when(
  data_pos_filter@phenoData$Outcome == "Discharge" ~ "Discharged",
  data_pos_filter@phenoData$Outcome == "Deceased" ~ "Deceased",
  data_pos_filter@phenoData$Outcome == "Ongoing (COV2 negative, currently in neuro rehab)" ~ "Discharged",
  TRUE ~ as.character(NA))

#ESI-
data_neg_filter@phenoData$Severe = case_when(
  data_neg_filter@phenoData$Severity == "Mild" ~ F,
  data_neg_filter@phenoData$Severity == "Int" ~ F,
  data_neg_filter@phenoData$Severity == "Severe" ~ T,
  TRUE ~ NA)

data_neg_filter@phenoData$SevereL = case_when(
  data_neg_filter@phenoData$Severity == "Mild" ~ "Mild",
  data_neg_filter@phenoData$Severity == "Int" ~ "Mild",
  data_neg_filter@phenoData$Severity == "Intermediate" ~ "Mild",
  data_neg_filter@phenoData$Severity == "Severe" ~ "Severe",
  TRUE ~ as.character(NA))

data_neg_filter@phenoData$Deceased = case_when(
  data_neg_filter@phenoData$Outcome == "Discharge" ~ F,
  data_neg_filter@phenoData$Outcome == "Deceased" ~ T,
  data_neg_filter@phenoData$Outcome == "Ongoing (COV2 negative, currently in neuro rehab)" ~ F,
  TRUE ~ NA)

data_neg_filter@phenoData$DeceasedL = case_when(
  data_neg_filter@phenoData$Outcome == "Discharge" ~ "Discharged",
  data_neg_filter@phenoData$Outcome == "Deceased" ~ "Deceased",
  data_neg_filter@phenoData$Outcome == "Ongoing (COV2 negative, currently in neuro rehab)" ~ "Discharged",
  TRUE ~ as.character(NA))

```



# Volcano plots
First p-values (including  q-values) and fold change is calculated with Mann-Whitney than shown in a custom volcano plot

```{r All by severity}
#ESI+
#Severity
t_start <- Sys.time()
volc_data_s_pos <- get_fold_pvalue_mw(data_pos_filter, "Severe")
Sys.time() -  t_start   

get_volcano_plot(volc_data_s_pos, add_lables = F, foldChange_lable_lim = 2.5, p_value_lable_lim = 0.05, use_q_value = T)

#Outcome
t_start <- Sys.time()
volc_data_d_pos <- get_fold_pvalue_mw(data_pos_filter, "Deceased")
Sys.time() - t_start   

get_volcano_plot(volc_data_d_pos, add_lables = F, foldChange_lable_lim = 2.5, p_value_lable_lim = 0.05, use_q_value = T)

#ESI-
#Severity
t_start <- Sys.time()
volc_data_s_neg <- get_fold_pvalue_mw(data_neg_filter, "Severe")
Sys.time() -  t_start   

get_volcano_plot(volc_data_s_neg, add_lables = F, foldChange_lable_lim = 2.5, p_value_lable_lim = 0.05, use_q_value = T)

#Outcome
t_start <- Sys.time()
volc_data_d_neg <- get_fold_pvalue_mw(data_neg_filter, "Deceased")
Sys.time() - t_start   

get_volcano_plot(volc_data_d_neg, add_lables = F, foldChange_lable_lim = 2.5, p_value_lable_lim = 0.05, use_q_value = T)

```

Get the lowest q_value compounds per ESI mode and label of interest
```{r}
checkComp_s_pos <- volc_data_s_pos %>% filter(abs(FoldChangeLog2) > 0.5 & Q_value < 0.05) %>% arrange(desc(abs(FoldChangeLog2)))
checkComp_d_pos <- volc_data_d_pos %>% filter(abs(FoldChangeLog2) > 0.5 & Q_value < 0.05) %>% arrange(desc(abs(FoldChangeLog2)))

checkComp_s_neg <- volc_data_s_neg %>% filter(abs(FoldChangeLog2) > 0.5 & Q_value < 0.05) %>% arrange(desc(abs(FoldChangeLog2)))
checkComp_d_neg <- volc_data_d_neg %>% filter(abs(FoldChangeLog2) > 0.5 & Q_value < 0.05) %>% arrange(desc(abs(FoldChangeLog2)))

#ESI+ severity
comp <- (checkComp_s_pos %>% arrange(Q_value) %>% pull(Compound))[1]
temp <- volc_data_s_pos %>% filter(Compound == comp)
sub = glue("Q value = {format(temp$Q_value, digits = 3)}  /  Log2 Fold Change = {format(temp$FoldChangeLog2, digits = 3)}")
getBoxPlotForCompound(data_pos_filter, comp, y_log = T, "Severe", subtitle = sub)

#ESI+ outcome
comp <- (checkComp_d_pos %>% arrange(Q_value) %>% pull(Compound))[1]
temp <- volc_data_d_pos %>% filter(Compound == comp)
sub = glue("Q value = {format(temp$Q_value, digits = 3)}  /  Log2 Fold Change = {format(temp$FoldChangeLog2, digits = 3)}")
getBoxPlotForCompound(data_pos_filter, comp, y_log = T, "Deceased", subtitle = sub)

#ESI- severity
comp <- (checkComp_s_neg %>% arrange(Q_value) %>% pull(Compound))[1]
temp <- volc_data_s_neg %>% filter(Compound == comp)
sub = glue("Q value = {format(temp$Q_value, digits = 3)}  /  Log2 Fold Change = {format(temp$FoldChangeLog2, digits = 3)}")
getBoxPlotForCompound(data_neg_filter, comp, y_log = T, "Severe", subtitle = sub)

#ESI- outcome
comp <- (checkComp_d_neg %>% arrange(Q_value) %>% pull(Compound))[1]
temp <- volc_data_d_neg %>% filter(Compound == comp)
sub = glue("Q value = {format(temp$Q_value, digits = 3)}  /  Log2 Fold Change = {format(temp$FoldChangeLog2, digits = 3)}")
getBoxPlotForCompound(data_neg_filter, comp, y_log = T, "Deceased", subtitle = sub)
```


Compounds curation step is taking place at this point. Looking at the union of the individually significant compounds (checkComp_s_pos, checkComp_d_pos, checkComp_s_neg, checkComp_d_neg) in Compound discoverer to select compounds that have good signal (LC chormatogram, isotopic pattern and preferential abducts). The subset of curated compounds is imported back for the continuation of the analysis. 


```{r}
significant_curated_pos_526 <- read_csv("Data/DiscoveryStudyB2-B5_Pos_curated_526.csv", guess_max = 8000)  
significant_curated_neg_409 <- read_csv("Data/DiscoveryStudyB2-B5_Neg_curated_409.csv", guess_max = 8000)

significant_curated_pos_526 %<>% 
  mutate(MW = significant_curated_pos_526$`Molecular Weight`) %>%
  mutate(RT = significant_curated_pos_526$`RT [min]`) %>%
  mutate(Compound = paste(MW, RT, sep = "_"))
sub_set_526 <- significant_curated_pos_526$Compound

significant_curated_neg_409 %<>% 
  mutate(MW = significant_curated_neg_409$`Molecular Weight`) %>%
  mutate(RT = significant_curated_neg_409$`RT [min]`) %>%
  mutate(Compound = paste(MW, RT, sep = "_"))
sub_set_409 <- significant_curated_neg_409$Compound
```


## Export for metaboAnalyst- Mummichog
A MUMMICHOG run in Metaboalalyst has been performed here to check pathway correlations 
The following code exports the significant and curated compounds into a format suitable for MUMMICHOG
Please note that we export the monoisotopic mass as M+H ions therefore only M+H abducts should be selected in MUMMICHOG

Feel free to extend to other ESI group and labels, if you extend to ESI- please adapt the m/z calculation to M-H ions
```{r}
sub_set_curated_s_pos <- checkComp_s_pos %>% filter(Compound %in% sub_set_526) %>% 
  select(c(Compound, Q_value)) %>% 
  dplyr::rename(p.value = Q_value) %>%
  separate(Compound, into = c("MW", "RT"), sep = "_") %>%
  mutate(m.z = as.numeric(MW) + 1.007276) %>% # -1.007276 for ESI-
  select(m.z, p.value) 

write.csv(sub_set_curated_s_pos, file = "DiscoveryStudy_B2-B5_curated_MetaboAnalyst_mummichog_severity_filter_526.csv")

```


# Models building

The following compounds were retained based on contribution to pathways or other known biological function 

## Compounds selection
Pyrimidines
ESI+
111.0431_0.919 dCytidine 
112.02713_1.081 Uracil
132.05334_0.844 Ureidopropionate

ESI-
244.06957_0.858 Pseudouridine 
244.06964_1.091 Uridine 

Kynurenine pathway
ESI+
208.08465_2.257  L-Kynurenine
204.08968_4.606 L-Tryptophan
362.20899_8.08 Cortisol 
122.04786_1.06 Nicotinamide
180.05336_4.775 Unknown (initially tought to be Nicotinuric acid)

ESI-
189.04276_5.294  Kynurenate

Acylcarnitines ESI+

Others ESI+

187.16826_0.684	N(1)-acetylspermidine
174.11151_0.679	DL-Arginine
384.12137_1.347	S-Adenosylhomocysteine
113.05879_0.728	Creatinine

```{r}
pyrimidine_pos <- c("111.0431_0.919", "112.02713_1.081" , "132.05334_0.844") 
pyrimidine_neg <- c("244.06957_0.858", "244.06964_1.091")

kynurenine_pos <- c("208.08465_2.257", "204.08968_4.606", "362.20899_8.08", "122.04786_1.06", "180.05336_4.775")
kynurenine_neg <- c("189.04276_5.294")

carnitines <- c("217.13131_1.629", "231.14698_4.286", "247.14186_1.208", "259.17833_6.403", "287.20948_7.961")

other_compounds_pos <- c("187.16826_0.684", "174.11151_0.679", "384.12137_1.347", "113.05879_0.728")

# 20 compounds model
selection_pos <- c(pyrimidine_pos, kynurenine_pos, carnitines, other_compounds_pos)
selection_neg <- c(pyrimidine_neg, kynurenine_neg)

#All curated compounds
curated_pos <- significant_curated_pos_526 %>% pull(Compound)
curated_neg <- significant_curated_neg_409 %>% pull(Compound)
```


## Preparing data for model building 
ESI+ and ESI- data will be merged
Separation in training and test sets 
Data will be scaled
Two labels will be retained for now LabelS (severity) LabelD (outcome)
Weights will be calculated (as the data is imbalanced especially in outcome)

The model data is cut to the 20 compounds model (selection_pos, selection_neg). To run model creation on different number of compounds please replace those in the following code with a different compounds selection. Per example curated_pos and curated_neg for the total of curated data (935 compounds)

```{r Data prep2}
pure_data <- data.frame()

data_pos <- t(exprs(data_pos_filter)) %>% as.data.frame() %>% 
  select(all_of(selection_pos)) %>%
  rownames_to_column(var = "Sample") %>%
  left_join(pData(data_pos_filter) %>% select(c(Sample, Deceased, Severity, Group, Sex))) %>% 
  filter(Group == "Sample" & !grepl("AA", Sample, fixed=TRUE)) %>% # do not take replicates (Sample names containing 'AA') as they don't have severity matched
  mutate(Sex = as.factor(Sex)) %>%
  select(-Sex) %>% #if one whan't to keep sex as a predicitor comment this line
  select(-Group) 

data_neg <- t(exprs(data_neg_filter)) %>% as.data.frame() %>% 
  select(all_of(selection_neg)) %>%
  rownames_to_column(var = "Sample") %>%
  left_join(pData(data_pos_filter) %>% select(c(Sample, Deceased, Severity, Group))) %>% 
  filter(Group == "Sample" & !grepl("AA", Sample, fixed=TRUE)) %>% # do not take replicates (Sample names containing 'AA') as they don't have severity matched
  select(-c(Group, Deceased, Severity))
  
pure_data <-  data_pos %>% left_join(data_neg, by = "Sample") %>%
  mutate(LabelD = Deceased) %>%
  mutate(LabelS = if_else(Severity=="Severe", T, F)) %>%
  select(-c(Deceased, Severity))  %>%
  drop_na() 

pure_data_z <- pure_data %>% mutate_if(is.numeric, scale)

set.seed(585)
train_rows <- get_train_rows2(pure_data_z, 0.8, "LabelS", "LabelD")

pure_data_train <- pure_data_z[train_rows,]
pure_data_test <- pure_data_z[-train_rows,]
data_out <- as.matrix(pure_data_train %>% select(-c(LabelD, LabelS)))

#Calculate weights
N_neg_D <- pure_data_train %>% filter(LabelD==F) %>% nrow
N_pos_D <- pure_data_train %>% filter(LabelD==T) %>% nrow
N_neg_S <- pure_data_train %>% filter(LabelS==F) %>% nrow
N_pos_S <- pure_data_train %>% filter(LabelS==T) %>% nrow

pos_weight_out_D = N_neg_D/N_pos_D
pos_weight_out_S = N_neg_S/N_pos_S

pos_weight_test_out = (pure_data_test %>% filter(LabelD==F) %>% nrow)/(pure_data_test %>% filter(LabelD==T) %>% nrow)
pos_weight_test_sev = (pure_data_test %>% filter(LabelS==F) %>% nrow)/(pure_data_test %>% filter(LabelS==T) %>% nrow)

weight_out <- ifelse(pure_data_train$LabelD, N_neg_D/(N_neg_D+N_pos_D), N_pos_D/(N_neg_D+N_pos_D))
weight_sev <- ifelse(pure_data_train$LabelS, N_neg_S/(N_neg_S+N_pos_S), N_pos_S/(N_neg_S+N_pos_S))
```

The following model building code will be ran multiple times (to adapt on different labels i.e., severity or outcome)

Choose Severity or Outcome by commenting / commenting the lines at the start of the next code chunk
```{r}
by <- "Severity"
#by <- "Outcome"

if(by == "Severity") {
  pure_data <- pure_data_z %>%
    mutate(Label = LabelS)
  pure_data_train <- pure_data_train %>%
    mutate(Label = LabelS) 
  pure_data_test <- pure_data_test %>%
    mutate(Label = LabelS)
  weight <- weight_sev
} else{
  pure_data <- pure_data_z %>%
    mutate(Label = LabelD)
  pure_data_train <- pure_data_train %>%
    mutate(Label = LabelD) 
  pure_data_test <- pure_data_test %>%
    mutate(Label = LabelD) 
  weight <- weight_out
}

pure_data <- pure_data %>%
  select(-c(LabelD, LabelS, Sample))
pure_data_train <- pure_data_train %>%
  select(-c(LabelD, LabelS, Sample))
pure_data_test <- pure_data_test %>%
  select(-c(LabelD, LabelS, Sample))

data_train_m <- as.matrix(pure_data_train %>% select(-Label))


#pure_data_sev_z <- pure_data
pure_data_out_z <- pure_data
```


```{r}
library(rstanarm)
library(yardstick)
library(pROC)
library(xgboost)
library(DiagrammeR)
library(glmnet)
```


## R stan arm model

Need to select a subset - very lengthly 
Can use unscaled data - will be scaled by the stanarm glm

Use of weights provides better results in outcome as the data is unbalanced
```{r Rstanarm}

set.seed(502)

options(mc.cores = parallel::detectCores())
t_start <- Sys.time()
sglm_r <- stan_glm(Label ~ ., family = binomial(), data = pure_data_train, prior = normal(scale = 1))#, weights = weight)
Sys.time() - t_start   

build_metrics_stan<-function(data) {
  res <- posterior_predict(sglm_r, newdata = (data %>% select(-Label)))
  res_mean <- apply(res, MARGIN = 2, mean)
  
  #prior <- N_neg/(N_neg+N_pos)
  prior <- 0.5
  #prior <- N_neg / N_pos
  levels <- c(T,F)
  data.frame(pred = res_mean,
             truth = factor(data$Label, levels=levels),
             pred_class = factor(res_mean>prior, levels=levels)) #%>%
    #rename(pred = X1)
}

train_metrics <- build_metrics_stan(pure_data_train)
train_metrics %>% conf_mat(truth, pred_class) 
train_metrics %>% roc_curve(truth,pred) %>% autoplot()
train_metrics %>% conf_mat(truth,pred_class) %>% summary

test_metrics <- build_metrics_stan(pure_data_test) 
test_metrics %>% conf_mat(truth,pred_class) 
test_metrics %>% roc_auc(truth, pred)
test_metrics %>% roc_curve(truth,pred) %>% autoplot()
test_metrics %>% conf_mat(truth,pred_class) %>% summary

get_roc_interval <- function(data) {
  
  roc_res <- data.frame()
  
  for(i in 1:500) {
    res <- posterior_predict(sglm, newdata = (data %>% select(-Label)))
    res_mean <- apply(res, MARGIN = 2, mean)
    
    prior <- 0.5
    levels <- c(T,F)
    data_pred <- data.frame(pred = res_mean,
             truth = factor(data$Label, levels=levels),
             pred_class = factor(res_mean>prior, levels=levels))
    
    roc <- roc(truth ~ pred, data = data_pred)
    roc_res <- roc_res %>% rbind(pROC::coords(roc, x = seq(from = 0, to = 1, by = 0.05)))
  }
  roc_res
}


par(pty="s")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for stan glm",
            ci=TRUE, boot.n=2000, plot=TRUE)

sens.ci <- ci.se(roc1, specificities=seq(0, 100, 5))
plot(sens.ci, type="shape", col="lightblue")


par(pty="m")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for stan glm",
            ci=TRUE, boot.n=2000, plot=TRUE, print.auc=T)


loo1 <- loo( sglm_r, cores = 1)
plot(loo1)
```

Run this chunk to visualize the model in browser 
The browser needs to be closed in order to continue
```{r}
launch_shinystan(sglm_r)
```



Monte-Carlo test on the model 

```{r}
source("Models_toolbox.R")
get_mc_stan_accuracy(100, pure_data)
```


## XGboost model

```{r xg boost Cross Validate}
set.seed(153)
params_tree <- list(objective = "binary:logistic", booster="gbtree", eta = 0.01, max_depth = 2)#, scale_pos_weight= pos_weight_out)
params_lin  <- list(objective = "binary:logistic", booster="gblinear")#, lambda=0.2, scale_pos_weight=N_neg/N_pos)

pure_data_train_m <- pure_data_train %>% select(-Label) %>% as.matrix()
params <- params_tree

xg_cv <- xgb.cv(params = params, data = pure_data_train_m, 
             label = pure_data_train$Label,
             nfold = 5, nrounds = 1000)


xg_cv$evaluation_log %>% ggplot() + 
  geom_point(aes(x = iter, y = train_logloss_mean), color = "red") + 
  geom_point(aes(x = iter, y = test_logloss_mean), color = "green")

```

Select the nrounds based on the evaluation plot in previous chunk
```{r xg boost Train}

set.seed(153)

xg <- xgboost(params = params, data = pure_data_train_m, 
             label = pure_data_train$Label,
             nrounds = 200)

build_metrics_xg<-function(data) {
  pred <- predict(xg,newdata = as.matrix(data %>% select(-Label)))
  #prior <- N_neg/(N_neg+N_pos)
  prior <- 0.5
  levels <- c(T,F)
  data.frame(pred=pred, 
             truth=factor(data$Label, levels=levels),
             pred_class=factor(pred>prior, levels=levels))
}

train_metrics <- build_metrics_xg(pure_data_train)
train_metrics %>% conf_mat(truth,pred_class) 
train_metrics %>% roc_curve(truth,pred) %>% autoplot()
train_metrics %>% conf_mat(truth,pred_class) %>% summary

test_metrics <- build_metrics_xg(pure_data_test)
test_metrics %>% conf_mat(truth,pred_class) 
test_metrics %>% roc_auc(truth, pred)
test_metrics %>% roc_curve(truth,pred) %>% autoplot()
test_metrics %>% conf_mat(truth,pred_class) %>% summary

importance<-xgb.importance(model=xg)
xgb.plot.importance(importance, rel_to_first = T)

par(pty="s")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for xgboost",
            ci=TRUE, boot.n=2000 , ci.alpha=0.5, plot=TRUE)

sens.ci <- ci.se(roc1, specificities=seq(0, 100, 5))
plot(sens.ci, type="shape", col="lightblue")


par(pty="m")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for xgboost",
            ci=TRUE, boot.n=2000, plot=TRUE, print.auc=T)


xgb.plot.tree(model = xg, trees = 0, show_node_id = TRUE)
```


## Elasticnet model 


```{r elastic train}
set.seed(542)
glmnet1<-cv.glmnet(x=as.matrix(pure_data_train %>% select(-Label)),
                   y=pure_data_train$Label,
                   nfolds = 5,
                   family = "binomial",
                   #lambda = seq(from = 0.1, to = 20, by =0.1),
                   #weights = weight, 
                   alpha = 0.1)
plot(glmnet1)

build_metrics_elastic<-function(data) {
  res <- predict(glmnet1,newx=as.matrix(data %>% select(-Label)),type="response")
  prior <- 0.5
  levels <- c(T,F)
  data.frame(pred = res[,1],
             truth = factor(data$Label, levels=levels),
             pred_class = factor(res>prior, levels=levels)) 
}

train_metrics <- build_metrics_elastic(pure_data_train)
train_metrics %>% conf_mat(truth, pred_class) 
train_metrics %>% roc_curve(truth,pred) %>% autoplot()
train_metrics %>% conf_mat(truth,pred_class) %>% summary

test_metrics <- build_metrics_elastic(pure_data_test)
test_metrics %>% conf_mat(truth,pred_class) 
test_metrics %>% roc_curve(truth,pred) %>% autoplot()
test_metrics %>% roc_auc(truth, pred)
test_metrics %>% conf_mat(truth,pred_class) %>% summary

par(pty="s")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for glmnet",
            ci=TRUE, boot.n=2000, plot=TRUE)

sens.ci <- ci.se(roc1, specificities=seq(0, 100, 5))
plot(sens.ci, type="shape", col="lightblue")
#plot(sens.ci, type="bars")

par(pty="m")
roc1 <- pROC::roc(truth ~ pred, test_metrics, percent=T, smooth = F, 
                  main="ROC with confidence intervals for glmnet",
            ci=TRUE, boot.n=2000, plot=TRUE, print.auc=T)

sens.ci <- ci.se(roc1, specificities=seq(0, 100, 5))
```



# Adjusted logistic regression

```{r}
getAdjustedLogistic <- function(data, df_comp, regress_by) {

  data@phenoData$LiverD = case_when(
    !is.na(data@phenoData$`Liver disease`) ~ T,
    TRUE ~ F)

  data@phenoData$CarD = case_when(
    !is.na(data@phenoData$`Cardiac disease`) ~ T,
    TRUE ~ F)

  data@phenoData$HTND = case_when(
    !is.na(data@phenoData$HTN) ~ T,
    TRUE ~ F)

  data@phenoData$KidneyD = case_when(
    !is.na(data@phenoData$`CKD (stage)`) ~ T,
    TRUE ~ F)

  data@phenoData$DM = case_when(
    !is.na(data@phenoData$`CKD (stage)`) ~ T,
    TRUE ~ F)

  no_ad_res <- data.frame()
  age_res <- data.frame()
  gender_res <- data.frame()
  bmi_res <- data.frame()
  liverD_res <- data.frame()
  carD_res <- data.frame()
  htn_res <- data.frame()
  kidneyD_res <- data.frame()
  DM1_res <- data.frame()
  DM2_res <- data.frame()
  DM_res <- data.frame()
  #Mal_res <- data.frame()
  all_res <- data.frame()

  for(compound in df_comp$Compound) {
    print(compound)
    no_ad_res <- no_ad_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound))
    age_res <- age_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "Age"))
    gender_res <- gender_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "Sex"))
    bmi_res <- bmi_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "BMI"))
    liverD_res <- liverD_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "LiverD"))
    carD_res <- carD_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "CarD"))
    htn_res <- htn_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "HTND"))
    kidneyD_res <- kidneyD_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "KidneyD"))
    DM_res <- DM_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = "DM"))
    all_res <- all_res %>% rbind(get_compound_logistic_reg(data, regress_by, compound, corrected_for = c("Age", "Sex", "BMI", "LiverD", "CarD", "HTND", "KidneyD", "DM")))
  }

  add_prefix <- function(p, s) {if_else(s != "Compound", glue("{p}{s}"), s)}

  adjsuted_results <- df_comp %>%
    left_join(no_ad_res %>% dplyr::rename_with(function(s)add_prefix("none_",s)), by ="Compound") %>%
    left_join(age_res %>% dplyr::rename_with(function(s)add_prefix("age_",s)), by="Compound") %>%
    left_join(gender_res %>% dplyr::rename_with(function(s)add_prefix("gender_",s)), by="Compound") %>%
    left_join(bmi_res %>% dplyr::rename_with(function(s)add_prefix("bmi_",s)), by="Compound") %>%
    left_join(liverD_res %>% dplyr::rename_with(function(s)add_prefix("liverD_",s)), by="Compound") %>%
    left_join(carD_res %>% dplyr::rename_with(function(s)add_prefix("cardiacD_",s)), by="Compound") %>%
    left_join(htn_res %>% dplyr::rename_with(function(s)add_prefix("HTN_",s)), by="Compound") %>%
    left_join(kidneyD_res %>% dplyr::rename_with(function(s)add_prefix("kidneyD_",s)), by="Compound") %>%
    left_join(DM_res %>% dplyr::rename_with(function(s)add_prefix("DM_",s)), by="Compound") %>%
    left_join(all_res %>% dplyr::rename_with(function(s)add_prefix("all_", s)), by="Compound")

  return(adjsuted_results)
}
```


```{r}
regress_by <- "Severe"
#regress_by <- "Deceased"


fd_pos <- fData(data_pos_filter[data_pos_filter@featureData$Compound %in% selection_pos,])
df_comp_pos <- data.frame(Compound = fd_pos$Compound, Name = fd_pos$Name, Polarity = "ESI+")
df_comp_pos %<>% left_join(volc_data_s_pos %>% select(Compound, Q_value, FoldChange))
res_pos <- getAdjustedLogistic(data_pos_filter, df_comp_pos, regress_by)

fd_neg <- fData(data_neg_filter[data_neg_filter@featureData$Compound %in% selection_neg,])
df_comp_neg <- data.frame(Compound = fd_neg$Compound, Name = fd_neg$Name, Polarity = "ESI-")
df_comp_neg %<>% left_join(volc_data_s_neg %>% select(Compound, Q_value, FoldChange))
res_neg <- getAdjustedLogistic(data_neg_filter, df_comp_neg, regress_by)

res <- res_pos %>% rbind(res_neg)
res
```








